<!DOCTYPE html>
<html lang='zh'>
    <head>
        <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=yes">
<title>
  
     [读书笔记]《西瓜书》第五章 神经网络 补充四 |  Sweet House
  
</title>


  <meta name="description" content="Everyday is a holiday">


<meta name="bytedance-verification-code" content="MmXZwSvr8lAvM1hIXSkm" />

<meta name="author" content='[Ryuchen WangOO]'>

<link rel="icon" href='/favicon.ico'>


  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@1.22.0/themes/prism-dark.min.css">
  



  
      
        <link rel="stylesheet" href='/dist/main.4707e15c5ca4eab5da71.min.css'>
      
  


<link rel="stylesheet" href='/css/shortcodes.css'>

<link rel="canonical" href="https://ryuchen.club/posts/0x000026/"><meta property="og:title" content="[读书笔记]《西瓜书》第五章 神经网络 补充四" />
<meta property="og:description" content="周志华《机器学习》俗称西瓜书，自己的读书笔记 Chapter: 5 神经网络 补充四" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://ryuchen.club/posts/0x000026/" />
<meta property="og:image" content="https://ryuchen.club/machine-learning.jpg" />
<meta property="article:published_time" content="2020-11-20T19:13:42+08:00" />
<meta property="article:modified_time" content="2020-11-20T19:13:42+08:00" /><meta property="og:see_also" content="https://ryuchen.club/posts/0x000030/" /><meta property="og:see_also" content="https://ryuchen.club/posts/0x00002e/" /><meta property="og:see_also" content="https://ryuchen.club/posts/0x00002d/" /><meta property="og:see_also" content="https://ryuchen.club/posts/0x00002c/" /><meta property="og:see_also" content="https://ryuchen.club/posts/0x00002b/" /><meta property="og:see_also" content="https://ryuchen.club/posts/0x00002a/" />

<meta itemprop="name" content="[读书笔记]《西瓜书》第五章 神经网络 补充四">
<meta itemprop="description" content="周志华《机器学习》俗称西瓜书，自己的读书笔记 Chapter: 5 神经网络 补充四">
<meta itemprop="datePublished" content="2020-11-20T19:13:42+08:00" />
<meta itemprop="dateModified" content="2020-11-20T19:13:42+08:00" />
<meta itemprop="wordCount" content="758">
<meta itemprop="image" content="https://ryuchen.club/machine-learning.jpg">



<meta itemprop="keywords" content="周志华,神经网络,西瓜书," />

    </head>
    <body>
        
<nav class="navbar navbar-expand-md navbar-light bg-light fixed-top shadow-sm" id="navbar-main-menu">
    <div class="container">
        <a class="navbar-brand font-weight-bold" href="https://ryuchen.club"> >$ cd /home_</a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#main-menu" aria-controls="main-menu" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="main-menu">
            <ul class="navbar-nav ml-auto">
                    
                        <li class='nav-item'><a class="nav-link" href="/">首页</a></li>
                    
                        <li class='nav-item'><a class="nav-link" href="/posts/">博文</a></li>
                    
                        <li class='nav-item'><a class="nav-link" href="/projects/">项目</a></li>
                    
                        <li class='nav-item'><a class="nav-link" href="/snippet/">代码</a></li>
                    
                        <li class='nav-item'><a class="nav-link" href="/essay/">随笔</a></li>
                    
                        <li class='nav-item'><a class="nav-link" href="/gallery/">照片墙</a></li>
                    
                        <li class='nav-item'><a class="nav-link" href="/about/">关于</a></li>
                    
                
                <li class="nav-item"><a class="nav-link" href="https://github.com/Ryuchen" target="_blank">Github</a></li>
            </ul>
        </div>
    </div>
</nav>

        
<main class="content-page container pt-7 pb-5">
    
    <div class="row">
        <div class="col">
            <article>
                <div class="row justify-content-center">
                    <div class="col-lg-10">
                        <h1>[读书笔记]《西瓜书》第五章 神经网络 补充四</h1>
                        <div class="meta text-muted mb-3" style="text-align: right;">
                            
                            <p class="created text-muted text-uppercase font-weight-bold mb-1">November 20, 2020</p>
                            <span class="mr-2"><i class="fas fa-book-open mr-2"></i>2838</span>
                            <span><i class="fas fa-clock mr-2"></i>12 minutes and
                                54 seconds</span>
                        </div>
                        <div class="category my-3"><a class="badge badge-pill badge-light border mr-2" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">
                                    <i class="fas fa-tag mr-2"></i>机器学习
                                </a></div></div>
                </div><div class="row justify-content-center mb-3">
                                <div class="col-lg-10">
                                    <img data-src="/images/machine-learning_huda146d3825fc6d502e05b38609bff098_23368_900x500_fit_q75_box.jpg" class="img-fluid rounded mx-auto d-block" alt="[读书笔记]《西瓜书》第五章 神经网络 补充四">
                                </div>
                            </div><div class="row justify-content-center">
                    <div class="col-lg-10">
                        <div class="content">
                            <h2 id="第五章-神经网络-补充四">第五章 神经网络 补充四</h2>
<hr>
<p>神经网络是现在主流的机器学习处理问题的手段，因此需要更加细致的去学习，所以这里自己搜集了一些补充知识点，而且感觉应该需要拆分成几个小章节进行论述，因此这里会使用副标题</p>
<h2 id="反向传播算法">反向传播算法</h2>
<blockquote>
<p>PS: 这里本来想是进行整理一下的，自己学习过程中网上搜集的资料的，但是奈何大多数博文都是一大堆公式，看的人索然无味，但在自己准备着手开始自己写的时候，发现了一篇好文，简单清晰明了，没有一大堆的公式，于是翻译在此。</p>
<p>原文链接: <a href="https://leonardoaraujosantos.gitbook.io/artificial-inteligence/machine_learning/supervised_learning/backpropagation">Backpropagation</a></p>
</blockquote>
<h3 id="介绍">介绍</h3>
<p>Backpropagation is an algorithm that calculate the partial derivative of every node on your model (ex: Convnet, Neural network). Those partial derivatives are going to be used during the training phase of your model, where a loss function states how much far your are from the correct result. This error is propagated backward from the model output back to it&rsquo;s first layers. The backpropagation is more easily implemented if you structure your model as a computational graph.</p>
<hr>
<p>反向传播是一种计算机器学习模型（例如：Convnet，神经网络）中每个节点的偏导数的算法。这些偏导数将会在你训练模型的阶段中使用，当你的损失函数告诉你，你的模型结果现在距离真实值有多远时。这里的误差将会通过反向传播算法通过模型输出层一直传回第一层。在使用过程中，如果你的模型能够构造成计算图，那么反向传播算法的使用将会十分容易。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ryuchen/ImageBed@develop/2020/11/20/0eef9513ff3090ce7e3cb6f7c37766a8.webp" alt="img"></p>
<p>The most important thing to have in mind here is how to calculate the forward propagation of each block and it&rsquo;s gradient. Actually most of the deep learning libraries code is about implementing those gates forward/backward code.</p>
<hr>
<p>这里要记住的最重要的事情是如何计算每个块的前向传播及其梯度。实际上大多数深度学习的库都已经实现了前向传播和后向传播的功能。</p>
<h3 id="基本单元">基本单元</h3>
<p>Some examples of basic blocks are, add, multiply, exp, max. All we need to do is observe their forward and backward calculation</p>
<hr>
<p>基本块的一些示例是加，乘，乘，最大值。我们要做的就是观察它们的前向传播和后向传播的计算过程。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ryuchen/ImageBed@develop/2020/11/20/13484678d1126c66170bcd70e18b3473.webp" alt="img"></p>
<p><img src="https://cdn.jsdelivr.net/gh/Ryuchen/ImageBed@develop/2020/11/20/e0cb2d5307f33d721bec441cf6ba4c9f.webp" alt="img"></p>
<p><img src="https://cdn.jsdelivr.net/gh/Ryuchen/ImageBed@develop/2020/11/20/8eb9b65ec841bef4e6d583e1ac7db5b6.webp" alt="img"></p>
<p><img src="https://cdn.jsdelivr.net/gh/Ryuchen/ImageBed@develop/2020/11/20/37dfb79ebee612ab834690900ac6f627.webp" alt="img"></p>
<p>Some other derivatives:</p>
<hr>
<p>一些其他的导数公式：</p>
<p>$$f(x) = \frac{1}{x} \quad \rightarrow \quad \frac{df}{dx} = - \frac{1}{x^2} $$</p>
<p>$$f_c(x) = c + x \quad \rightarrow \quad \frac{df}{dx} = 1$$</p>
<p>$$f(x) = e^x \quad \rightarrow \quad \frac{df}{dx} = e^x$$</p>
<p>$$f_a(x) = ax \quad \rightarrow \quad \frac{df}{dx} = a$$</p>
<p>Observe that we output 2 gradients because we have 2 inputs&hellip; Also observe that we need to save (cache) on memory the previous inputs.</p>
<hr>
<p>观察到这里我们输出了2个梯度值，是因为我们有2个输入&hellip; 还观察到我们需要将先前的输入保存（缓存）在内存中。</p>
<h3 id="链式法则">链式法则</h3>
<p>Imagine that you have an output $y$, that is function of $g$, which is function of $f$, which is function of $x$. If you want to know how much $g$ will change with a small change on $dx(\frac{dg}{dx})$, we use the chain rule. Chain rule is a formula for computing the derivative of the composition of two or more functions.</p>
<hr>
<p>想象一下，您有一个输出 $y$，它是 $g$ 的函数输出，而 $g$ 又是 $f$ 的函数，$f$ 又是 $x$ 的函数。 如果您想知道 $g$ 随 $dx(\frac{dg}{dx})$ 的微小变化而变化多少，我们使用链式规则。 链规则是用于计算两个或多个函数组成的导数的公式。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ryuchen/ImageBed@develop/2020/11/20/28c9150db26dc5148a649c7fd3d1f74a.webp" alt="img"></p>
<p>The chain rule is the work horse of back-propagation, so it&rsquo;s important to understand it now. On the picture bellow we get a node $f(x,y)$ that compute some function with two inputs $x$ , $y$ and output $z$. Now on the right side, we have this same node receiving from somewhere (loss function) a gradient $dL/dz$ which means. &ldquo;How much $L$ will change with a small change on $z$&rdquo;. As the node has 2 inputs it will have 2 gradients. One showing how $L$ will a small change $dx$ and the other showing how $L$ will change with a small change $dz$</p>
<hr>
<p>链式规则是反向传播的工作原理，因此现在了解它非常重要。 在下面的图片中，我们得到一个节点 $f(x，y)$，该节点的函数用两个输入 $x$，$y$ 和输出 $z$ 计算。现在在右侧，该同一个节点从某处（损失函数）接收梯度 $dL/dz$ ，这意味着 “随着 $z$ 的微小变化，$L$ 会变化多少”。 由于节点具有2个输入，因此它将具有 $2$ 个梯度。一个显示 $L$ 如何随着 $dx$ 的小变化而变化，另一个显示 $L$ 如何随着 $dz$ 的小变化而变化</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ryuchen/ImageBed@develop/2020/11/20/d3ebbe829f0296834c73bda5bb8586c4.webp" alt="img"></p>
<p>In order to calculate the gradients we need the input $dL/dz$ ($dout$), and the derivative of the function $f(x,y)$, at that particular input, then we just multiply them. Also we need the previous cached input, saved during forward propagation.</p>
<hr>
<p>为了计算梯度，则我们需要计算 $dL/dz$ 的输入 和 $f(x, y)$ 的导数，并将其进行相乘，另外我们需要在前向传播的过程中在缓存中保存的输入。</p>
<h3 id="计算实现">计算实现</h3>
<p>Observe bellow the implementation of the multiply and add gate on python</p>
<hr>
<p>下面是乘法和加法的python实现</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ryuchen/ImageBed@develop/2020/11/20/3f4ec7db8e03f6ac90f6a0e4acf8ebf6.webp" alt="img"></p>
<h3 id="分布计算示例">分布计算示例</h3>
<p>With what we learn so far, let&rsquo;s calculate the partial derivatives of some graphs.</p>
<hr>
<p>通过到目前为止的学习，我们来计算一些图的偏导数。</p>
<h4 id="简单的例子">简单的例子</h4>
<p>Here we have a graph for the function $f(x,y,z) = (x+y)*z$</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ryuchen/ImageBed@develop/2020/11/20/ee1316b55cce61becae693ae21d8308c.webp" alt="img"></p>
<ol>
<li>Start from output node $f$, and consider that the gradient of $f$ related to some criteria is $1$.</li>
<li>$dq=(dout(1) *z)$, which is -4 (How the output will change with a change in $q$</li>
<li>$dz=(dout(1)* q)$, which is 3 (How the output will change with a change in $z$</li>
<li>The sum gate distribute it&rsquo;s input gradients, so $dx=-4$, $dy=-4$ (How the output will change with $x$, $z$)</li>
</ol>
<hr>
<blockquote>
<p>图示很清楚就不翻译了~</p>
</blockquote>
<h4 id="拥有两个输入的感知机">拥有两个输入的感知机</h4>
<p>This following graph represent the forward propagation of a simple 2 inputs, neural network with one output layer with sigmoid activation.</p>
<hr>
<p>下图表示一个简单的2输入神经网络的向前传播，该神经网络具有一个具有Sigmoid型激活函数的输出层。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ryuchen/ImageBed@develop/2020/11/20/97b3de7fd89094f6f7a1e90af886ecb4.webp" alt="img"></p>
<p><img src="https://cdn.jsdelivr.net/gh/Ryuchen/ImageBed@develop/2020/11/20/1f8b6def418add1a5828839e90e662de.webp" alt="img"></p>
<ol>
<li>Start from the output node, considering that or error($dout$) is $1$</li>
<li>The gradient of the input of the $1/x$ will be $-1/(1.37^2)$, $-0.53$</li>
<li>The increment node does not change the gradient on it&rsquo;s input, so it will be $(-0.53 * 1)$, $-0.53$</li>
<li>The exp node input gradient will be $(\exp(-1(\text{cached input})) * -0.53)$, $-0.2$</li>
<li>The negative gain node will be it&rsquo;s input gradient $(-1 * -0.2)$, $0.2$</li>
<li>The sum node will distribute the gradients, so, $dw2=0.2$, and the sum node also $0.2$</li>
<li>The sum node again distribute the gradients so again $0.2$</li>
<li>$dw0$ will be $(0.2 * -1)$, $-0.2$</li>
<li>$dx0$ will be $(0.2 * 2)$ , $0.4$</li>
</ol>
<h3 id="梯度消失与梯度爆炸">梯度消失与梯度爆炸</h3>
<blockquote>
<p>PS: 这里是补充的额外内容了~</p>
</blockquote>
<p><strong>梯度消失问题和梯度爆炸问题一般随着网络层数的增加会变得越来越明显。</strong></p>
<blockquote>
<p>PS: 这个注意下，梯度消失与梯度爆炸问题都是在反向传播的过程中，即从后向前传导的过程中出现的问题</p>
</blockquote>
<h4 id="梯度消失gradient-vanishing-problem">梯度消失（gradient vanishing problem）</h4>
<p><img src="https://cdn.jsdelivr.net/gh/Ryuchen/ImageBed@develop/2020/11/20/0c38c13feecfccb56ca808920cee89ab.webp" alt="img"></p>
<h4 id="梯度爆炸gradient-exploding-problem">梯度爆炸（gradient exploding problem）</h4>
<p>而梯度爆炸正好与上图所示的梯度消失的问题正好相反，当 $\text{abs}(w) \ge 1$ 时，那么层数增多的时候，最终的求出的梯度更新将以指数形式增加，即发生<strong>梯度爆炸</strong></p>
<h4 id="解决方案">解决方案</h4>
<p>（1）预训练加微调</p>
<p>此方法来自Hinton在2006年发表的一篇论文，Hinton为了解决梯度的问题，提出采取无监督逐层训练方法，其基本思想是每次训练一层隐节点，训练时将上一层隐节点的输出作为输入，而本层隐节点的输出作为下一层隐节点的输入，此过程是逐层“预训练”（pre-training）；在预训练完成后，再对整个网络进行“微调”（fine-tunning）。Hinton在训练深度信念网络（Deep Belief Networks中，使用了这个方法，在各层预训练完成后，再利用BP算法对整个网络进行训练。此思想相当于是先寻找局部最优，然后整合起来寻找全局最优，此方法有一定的好处，但是目前应用的不是很多了。</p>
<p>（2）梯度横截</p>
<p><strong>梯度横截</strong>这个方案主要是针对<strong>梯度爆炸</strong>提出的，其思想是设置一个梯度截断的阈值，然后更新梯度的时候，如果梯度超过这个阈值，那么就将其强制限制在这个范围之内。这可以防止梯度爆炸。</p>
<p>另外一种<strong>解决梯度爆炸的手段</strong>是采用<strong>权重正则化</strong>（weithts regularization）。</p>
<p>（3）使用 Relu 激活函数家族</p>
<p>Relu:思想也很简单，如果激活函数的导数为1，那么就会极大的降低梯度消失爆炸的问题了，每层的网络都可以得到相同的更新速度。</p>
<p>（4）批量标准化（Batch Normalization）</p>
<p>Batchnorm是深度学习发展以来提出的最重要的成果之一了，目前已经被广泛的应用到了各大网络中，具有加速网络收敛速度，提升训练稳定性的效果，Batchnorm本质上是解决反向传播过程中的梯度问题。batchnorm全名是batch normalization，简称BN，即批规范化，通过规范化操作将输出信号x规范化到均值为0，方差为1保证网络的稳定性。</p>
<p>（5）使用残差网络结构</p>
<p>（6）权重初始化时使用高斯初始化</p>
<h3 id="研究方向">研究方向</h3>
<p>BP网络 主要用于以下四个方面。</p>
<p>1)函数逼近：用输入向量和相应的输出向量训练一个网络逼近一个函数。</p>
<p>2)模式识别：用一个待定的输出向量将它与输入向量联系起来。</p>
<p>3)分类：把输入向量所定义的合适方式进行分类。</p>
<p>4)数据压缩：减少输出向量维数以便于传输或存储。</p>
<p>除此之外，在神经网络的可解释性研究方面，向低功耗硬件迁移，以及在认知计算，规划推理等方面和其他传统技术进行结合探索</p>
<h3 id="reference">Reference</h3>
<ul>
<li>
<p><a href="https://leonardoaraujosantos.gitbook.io/artificial-inteligence/machine_learning/supervised_learning/backpropagation">Backpropagation</a></p>
</li>
<li>
<p><a href="https://zhuanlan.zhihu.com/p/50010752">梯度消失和梯度爆炸</a></p>
</li>
<li>
<p><a href="https://zhuanlan.zhihu.com/p/38537439">深度学习中的激活函数与梯度消失、梯度爆炸</a></p>
</li>
<li>
<p><a href="https://www.jiqizhixin.com/graph/technologies/7332347c-8073-4783-bfc1-1698a6257db3">反向传播算法</a></p>
</li>
</ul>

                        </div><div class="tags my-3"><a class="badge badge-pill badge-light border mr-2" href="/tags/%E5%91%A8%E5%BF%97%E5%8D%8E/">
                                    <i class="fas fa-tag mr-2"></i>周志华
                                </a><a class="badge badge-pill badge-light border mr-2" href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">
                                    <i class="fas fa-tag mr-2"></i>神经网络
                                </a><a class="badge badge-pill badge-light border mr-2" href="/tags/%E8%A5%BF%E7%93%9C%E4%B9%A6/">
                                    <i class="fas fa-tag mr-2"></i>西瓜书
                                </a></div><div style="text-align: center;">
                            <div class="social-share" data-sites="wechat,weibo,twitter,facebook,douban" data-mobile-sites="wechat,weibo"></div>
                        </div>
                    </div>
                </div>

                <div class="row justify-content-center">
                    <div class="col-lg-8">
                        

<div id="comments-gittalk"></div>
    <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
    <script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script> 
    <script>
    var gittalk = new Gitalk({
        id: '0x000026',
        owner: 'Ryuchen',
        repo: 'ryuchen.github.io',
        admin: ['Ryuchen'],
        clientID: 'cda75f43f62ef6ebc3ea',
        clientSecret: 'e405fb603c664a6436a481917a7ee70931413268',
    })
    gittalk.render('comments-gittalk')
    </script>



                    </div>
                </div>
            </article>
        </div>
    </div>

    <div class="related-content row mt-5 row-cols-1 row-cols-lg-3"><div class="col mb-3">
                <div class="card h-100 shadow">
    
    <a href="/posts/0x000025/" class="d-block">
                        <img data-src="https://cdn.jsdelivr.net/gh/Ryuchen/ryuchen.github.io@master/images/machine-learning_huda146d3825fc6d502e05b38609bff098_23368_700x350_resize_q75_box.jpg" class="card-img-top mx-auto d-block" alt="[读书笔记]《西瓜书》第五章 神经网络 补充三">
                    <div class="card-body">
            <div class="card-title">
                [读书笔记]《西瓜书》第五章 神经网络 补充三
            </div><div class="card-serie"><span class="badge badge-pill badge-primary">机器学习</span> &nbsp;</div><p class="card-text text-muted text-uppercase">November 20, 2020</p>
            <div class="card-text">
                周志华《机器学习》俗称西瓜书，自己的读书笔记 Chapter: 5 神经网络 补充三
            </div>
        </div>
    </a>
</div>

            </div><div class="col mb-3">
                <div class="card h-100 shadow">
    
    <a href="/posts/0x000024/" class="d-block">
                        <img data-src="https://cdn.jsdelivr.net/gh/Ryuchen/ryuchen.github.io@master/images/machine-learning_huda146d3825fc6d502e05b38609bff098_23368_700x350_resize_q75_box.jpg" class="card-img-top mx-auto d-block" alt="[读书笔记]《西瓜书》第五章 神经网络 补充二">
                    <div class="card-body">
            <div class="card-title">
                [读书笔记]《西瓜书》第五章 神经网络 补充二
            </div><div class="card-serie"><span class="badge badge-pill badge-primary">机器学习</span> &nbsp;</div><p class="card-text text-muted text-uppercase">November 20, 2020</p>
            <div class="card-text">
                周志华《机器学习》俗称西瓜书，自己的读书笔记 Chapter: 5 神经网络 补充二
            </div>
        </div>
    </a>
</div>

            </div><div class="col mb-3">
                <div class="card h-100 shadow">
    
    <a href="/posts/0x000023/" class="d-block">
                        <img data-src="https://cdn.jsdelivr.net/gh/Ryuchen/ryuchen.github.io@master/images/machine-learning_huda146d3825fc6d502e05b38609bff098_23368_700x350_resize_q75_box.jpg" class="card-img-top mx-auto d-block" alt="[读书笔记]《西瓜书》第五章 神经网络 补充一">
                    <div class="card-body">
            <div class="card-title">
                [读书笔记]《西瓜书》第五章 神经网络 补充一
            </div><div class="card-serie"><span class="badge badge-pill badge-primary">机器学习</span> &nbsp;</div><p class="card-text text-muted text-uppercase">November 19, 2020</p>
            <div class="card-text">
                周志华《机器学习》俗称西瓜书，自己的读书笔记 Chapter: 5 神经网络 补充一
            </div>
        </div>
    </a>
</div>

            </div></div>
</main>

        <footer class="footer bg-dark py-6">
    <div class="container">
        <div class="row">
            <div class="col-sm text-center">
                <ul class="list-inline">
                    <li class="list-inline-item"><a href="https://ryuchen.club/index.xml" rel="alternate" type="application/rss+xml" class="icons d-block">
                                    <span class="fa-stack fa-lg">
                                        <i class="fa fa-circle fa-stack-2x"></i>
                                        <i class="fa fa-rss fa-stack-1x fa-inverse"></i>
                                    </span>
                                </a></li><li class="list-inline-item">
                        <a href="mailto:chenhaom1993@hotmail.com" class="icons d-block">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-envelope fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li><li class="list-inline-item">
                            <a href="https://github.com/Ryuchen" class="icons d-block">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li><li class="list-inline-item">
                            <a href="https://weibo.com/u/3147247770" class="icons d-block">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fab fa-weibo fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                </ul>

                <p class="text-muted">
                    
                        Copyright © 2018–2020, WangOO and Ryuchen, all rights reserved.
                    
                </p>

                <p class="text-muted">
                    京ICP备2020040667号
                </p>

                <p class="text-muted">
                    本站总记被访问 <span id="busuanzi_value_site_pv"></span> 次， 
                    您是第 <span id="busuanzi_value_site_uv"></span> 个来访小伙伴。
                </p>
            </div>
            <div class="col-sm text-center"><p class="text-muted">维护不易，渴望您的资助</p><ul class="list-inline">
                    <div class="row">
                        <div class="col-sm text-center"><li class="list-inline-item">
                                <img src="https://cdn.jsdelivr.net/gh/Ryuchen/ImageBed@sponsor/wechat.jpg" alt="WechatPay" class="loaded" data-was-processed="true" style="width: 140px;padding: 4px">
                            </li></div>
                        <div class="col-sm text-center"><li class="list-inline-item">
                                <img src="https://cdn.jsdelivr.net/gh/Ryuchen/ImageBed@sponsor/alipay.jpg" alt="AliPay" class="loaded" data-was-processed="true" style="width: 140px;padding: 4px">
                            </li></div>
                    </div>
                </ul>
            </div>
        </div>
    </div>
    <div class="netease-music">
            <audio id="music-player" crossorigin playsinline>
            </audio>
        </div>
    
</footer>

        
    
        
            <script src='/dist/main.bf9558b8596b4accd07a.min.js'></script>
        
    



<script src='https://cdn.jsdelivr.net/gh/Ryuchen/ryuchen.github.io@master//mermaid/mermaid.js'></script>



    <script>
        window.Prism = window.Prism || {};
    </script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.22.0/prism.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.22.0/plugins/autoloader/prism-autoloader.min.js"></script>




    <script>
  MathJax = {
    tex: {
      inlineMath: [["$", "$"]],
    },
    displayMath: [
      ["$$", "$$"],
      ["\[\[", "\]\]"],
    ],
    svg: {
      fontCache: "global",
    },
  };
</script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>


<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




    <script>
        (function(){
            var bp = document.createElement('script');
            var curProtocol = window.location.protocol.split(':')[0];
            if (curProtocol === 'https'){
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        }
        else{
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(bp, s);
        })();
    </script>


<script>
    (function(){
    var el = document.createElement("script");
    el.src = "https://s3a.pstatp.com/toutiao/push.js?1b349c44e658214c68be3a649c8dd67d03df3ccff5cf4d26c95620535e04d891417631efa03c64873bef9496a5c9bb7c62f7c4af6b1a55b161baff8a0b4e2fba";
    el.id = "ttzz";
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(el, s);
    })(window)
</script>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/css/share.min.css"  crossorigin="anonymous" />
<script src="https://cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/js/social-share.min.js" integrity="sha256-fGPu+icKh985TLPhO2v68U7i0CW0dE4kiR06RN4O6jo=" crossorigin="anonymous"></script>


<script async src="https://www.googletagmanager.com/gtag/js?id=G-0EFH27TG1R"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-0EFH27TG1R');
</script>
    </body>
</html>
